{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import numpy as np                                  # \"Scientific computing\"\n",
    "\n",
    "import pandas as pd                                 # Data Frame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import matplotlib.pyplot as plt                     # Basic visualisation\n",
    "\n",
    "import seaborn as sns                               # Advanced data visualisation\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>concave points</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_lg</th>\n",
       "      <th>texture_lg</th>\n",
       "      <th>perimeter_lg</th>\n",
       "      <th>area_lg</th>\n",
       "      <th>smoothness_lg</th>\n",
       "      <th>compactness_lg</th>\n",
       "      <th>concavity_lg</th>\n",
       "      <th>concave points_lg</th>\n",
       "      <th>symmetry_lg</th>\n",
       "      <th>fractal dimension_lg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius  texture  perimeter    area  smoothness  \\\n",
       "0    842517         M   20.57    17.77     132.90  1326.0     0.08474   \n",
       "1  84300903         M   19.69    21.25     130.00  1203.0     0.10960   \n",
       "2  84348301         M   11.42    20.38      77.58   386.1     0.14250   \n",
       "3  84358402         M   20.29    14.34     135.10  1297.0     0.10030   \n",
       "4    843786         M   12.45    15.70      82.57   477.1     0.12780   \n",
       "\n",
       "   compactness  concavity  concave points  ...  radius_lg  texture_lg  \\\n",
       "0      0.07864     0.0869         0.07017  ...      24.99       23.41   \n",
       "1      0.15990     0.1974         0.12790  ...      23.57       25.53   \n",
       "2      0.28390     0.2414         0.10520  ...      14.91       26.50   \n",
       "3      0.13280     0.1980         0.10430  ...      22.54       16.67   \n",
       "4      0.17000     0.1578         0.08089  ...      15.47       23.75   \n",
       "\n",
       "   perimeter_lg  area_lg  smoothness_lg  compactness_lg  concavity_lg  \\\n",
       "0        158.80   1956.0         0.1238          0.1866        0.2416   \n",
       "1        152.50   1709.0         0.1444          0.4245        0.4504   \n",
       "2         98.87    567.7         0.2098          0.8663        0.6869   \n",
       "3        152.20   1575.0         0.1374          0.2050        0.4000   \n",
       "4        103.40    741.6         0.1791          0.5249        0.5355   \n",
       "\n",
       "   concave points_lg  symmetry_lg  fractal dimension_lg  \n",
       "0             0.1860       0.2750               0.08902  \n",
       "1             0.2430       0.3613               0.08758  \n",
       "2             0.2575       0.6638               0.17300  \n",
       "3             0.1625       0.2364               0.07678  \n",
       "4             0.1741       0.3985               0.12440  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jdecorte/machinelearning/main/datasets/wdbc.csv')\n",
    "# !! it is really important to give each of the columns an (appropriate) name, \n",
    "# otherwise you will get an error: all-features-must-be-in-0-9-or-10-0\n",
    "# https://stackoverflow.com/questions/65789613/all-features-must-be-in-0-9-or-10-0\n",
    "df.columns = ['id','diagnosis','radius','texture','perimeter','area','smoothness','compactness','concavity','concave points','symmetry','fractal dimension','radius_std','texture_std','perimeter_std','area_std','smoothness_std','compactness_std','concavity_std','concave points_std','symmetry_std','fractal dimension_std','radius_lg','texture_lg','perimeter_lg','area_lg','smoothness_lg','compactness_lg','concavity_lg','concave points_lg','symmetry_lg','fractal dimension_lg']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model opbouwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'diagnosis'], axis = 1)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "col_transform = ColumnTransformer(transformers=[\n",
    "    ('standard_scaler', StandardScaler(), numerical_ix)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (142, 30) (426,) (142,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search met een SVM Classifier\n",
    "\n",
    "1. We willen de nauwkeurigheid voor elk van de vier classifiers weten. We willen vier classifiers testen: Logistische regressie, een RandomForestClassifier, een SVMClassifier en een Voting Classifier die de vorige drie classifiers gaat meegeven. Voor de voting classifier wordt er gewerkt met een 'harde' vote. We slaan elke classifier op in een array.\n",
    "* Hard voting is wanneer we de voorspelling met het hoogst aantal stemmen gaan nemen. Soft voting is waarbij we de kansen gaan combineren per model en waarvan we de meest waarschijnlijke kans gaan nemen.\n",
    "\n",
    "2. We willen iedere classifier testen op nauwkeurigheid. Hiervoor moeten we een for-lus gebruiken waarbij we iedere tuple van de array gaan afgaan.\n",
    "2. We bouwen de Pipeline op met daarin de columntransformer en de classifier die we willen testen.\n",
    "2. We trainen de pipeline en voorspellen labels op basis van de X_testset.\n",
    "2. We bouwen een confusion matrix op. We zitten hier met binaire classifiers, dus we moeten .ravel() toevoegen aan de confusion matrix.\n",
    "2. We printen de accuracy-score en de waarden uit de confusion matrix uit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "vot_clf = VotingClassifier(estimators=[\n",
    "    ('log_clf', log_clf),\n",
    "    ('rnd_clf', rnd_clf),\n",
    "    ('svm_clf', svm_clf)], voting='hard')\n",
    "\n",
    "all_clf = [('log_clf', log_clf), ('rnd_clf', rnd_clf), ('svm_clf', svm_clf), ('vot_clf', vot_clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_clf accuracy_score = 96.48%  TN = 85   FP = 2   FN = 3   TP = 52\n",
      "rnd_clf accuracy_score = 96.48%  TN = 85   FP = 2   FN = 3   TP = 52\n",
      "svm_clf accuracy_score = 96.48%  TN = 86   FP = 1   FN = 4   TP = 51\n",
      "vot_clf accuracy_score = 96.48%  TN = 85   FP = 2   FN = 3   TP = 52\n"
     ]
    }
   ],
   "source": [
    "for clf_tuple in all_clf:\n",
    "  pipeline = Pipeline([\n",
    "    ('prep',col_transform), \n",
    "    (clf_tuple[0], clf_tuple[1])\n",
    "    ])\n",
    "\n",
    "  pipeline.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = pipeline.predict(X_test)\n",
    "  \n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "  print(f\"{clf_tuple[0]} accuracy_score = {accuracy_score(y_test, y_pred):.2%}  TN = {tn}   FP = {fp}   FN = {fn}   TP = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search met een niet-lineaire classifier:\n",
    "\n",
    "We passen de code van daarnet aan. We hebben enkel de SVMClassifier van daarnet niet meer nodig. Deze gaan we vervangen door een niet-lineaire SVM classifier.\n",
    "\n",
    "De stappen herhalen zich hier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_clf accuracy_score = 0.9647887323943662  TN = 85   FP = 2   FN = 3   TP = 52\n",
      "rnd_clf accuracy_score = 0.9647887323943662  TN = 85   FP = 2   FN = 3   TP = 52\n",
      "svm_clf accuracy_score = 0.9788732394366197  TN = 87   FP = 0   FN = 3   TP = 52\n",
      "vot_clf accuracy_score = 0.971830985915493  TN = 86   FP = 1   FN = 3   TP = 52\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(C=1, coef0=1, degree=2, kernel='poly', random_state=42)\n",
    "\n",
    "vot_clf = VotingClassifier(estimators=[\n",
    "  ('log_clf', log_clf),\n",
    "  ('rnd_clf', rnd_clf),\n",
    "  ('svm_clf', svm_clf)], voting='hard')\n",
    "\n",
    "all_clf = [('log_clf', log_clf), ('rnd_clf', rnd_clf), ('svm_clf', svm_clf), ('vot_clf', vot_clf)]\n",
    "\n",
    "for clf_tuple in all_clf:\n",
    "  pipeline = Pipeline([\n",
    "    ('prep',col_transform), \n",
    "    (clf_tuple[0], clf_tuple[1])\n",
    "])\n",
    "\n",
    "  pipeline.fit(X_train, y_train)\n",
    "  y_pred = pipeline.predict(X_test)\n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "  print(f\"{clf_tuple[0]} accuracy_score = {accuracy_score(y_test, y_pred)}  TN = {tn}   FP = {fp}   FN = {fn}   TP = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search voor een Random Forest Classifier\n",
    "\n",
    "Voor de RFC hebben we eerst een grid van parameters nodig. De estimators, maximaal aantal bladen en maximale diepte werden niet gegeven. \n",
    "\n",
    "1. We stellen een dictionary op van parameters die we willen gebruiken voor de GridSearch.\n",
    "2. We maken een GridSearch-object aan bedoeld voor een RandomForestClassifier.\n",
    "3. We bouwen een pipeline op met (net zoals bij de vorige twee GridSearches) eerst een columntransformer, gevolgd door de GridSearch.\n",
    "4. We trainen de pipeline met de trainingsdata (X en y).\n",
    "5. Als laatste vragen we de beste estimator en score op van de GridSearch. De best estimator kan later ingezet worden als model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator = RandomForestClassifier(max_depth=6, max_leaf_nodes=10, n_estimators=200,\n",
      "                       random_state=42)\n",
      "best score = 0.9577464788732394\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 400, 600],\n",
    "    'max_leaf_nodes': [2, 4, 6, 10, 14, 16, 18],\n",
    "    'max_depth' : [2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "grid_svc = GridSearchCV(RandomForestClassifier(random_state = 42), param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('prep',col_transform),\n",
    "    ('grid_svc', grid_svc)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(f\"best estimator = {grid_svc.best_estimator_}\")\n",
    "print(f\"best score = {grid_svc.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra:\n",
    "Het getrainde GridSearch-object geeft ons de mogelijkheid om de importance per feature op te vragen. Hieronder bouwen we een dataframe op met daarin per kolomnaam de feature importance.\n",
    "1. We hebben twee variabelen: 'column_name' waar we de features van de trainingsset gaan meegeven. 'importance' waar we de feature importance gaan opvragen per feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius</td>\n",
       "      <td>0.060664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture</td>\n",
       "      <td>0.013522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter</td>\n",
       "      <td>0.069634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area</td>\n",
       "      <td>0.059164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness</td>\n",
       "      <td>0.003836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness</td>\n",
       "      <td>0.011219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity</td>\n",
       "      <td>0.041026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points</td>\n",
       "      <td>0.085093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry</td>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal dimension</td>\n",
       "      <td>0.002150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_std</td>\n",
       "      <td>0.010155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_std</td>\n",
       "      <td>0.004696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_std</td>\n",
       "      <td>0.006506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_std</td>\n",
       "      <td>0.025854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_std</td>\n",
       "      <td>0.002699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_std</td>\n",
       "      <td>0.001838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_std</td>\n",
       "      <td>0.007887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_std</td>\n",
       "      <td>0.003426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_std</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal dimension_std</td>\n",
       "      <td>0.005041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_lg</td>\n",
       "      <td>0.080672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_lg</td>\n",
       "      <td>0.016705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_lg</td>\n",
       "      <td>0.159605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_lg</td>\n",
       "      <td>0.147641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_lg</td>\n",
       "      <td>0.010749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_lg</td>\n",
       "      <td>0.017488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_lg</td>\n",
       "      <td>0.033313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_lg</td>\n",
       "      <td>0.102010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_lg</td>\n",
       "      <td>0.009165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal dimension_lg</td>\n",
       "      <td>0.004870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column_name  importance\n",
       "0                  radius    0.060664\n",
       "1                 texture    0.013522\n",
       "2               perimeter    0.069634\n",
       "3                    area    0.059164\n",
       "4              smoothness    0.003836\n",
       "5             compactness    0.011219\n",
       "6               concavity    0.041026\n",
       "7          concave points    0.085093\n",
       "8                symmetry    0.001944\n",
       "9       fractal dimension    0.002150\n",
       "10             radius_std    0.010155\n",
       "11            texture_std    0.004696\n",
       "12          perimeter_std    0.006506\n",
       "13               area_std    0.025854\n",
       "14         smoothness_std    0.002699\n",
       "15        compactness_std    0.001838\n",
       "16          concavity_std    0.007887\n",
       "17     concave points_std    0.003426\n",
       "18           symmetry_std    0.001429\n",
       "19  fractal dimension_std    0.005041\n",
       "20              radius_lg    0.080672\n",
       "21             texture_lg    0.016705\n",
       "22           perimeter_lg    0.159605\n",
       "23                area_lg    0.147641\n",
       "24          smoothness_lg    0.010749\n",
       "25         compactness_lg    0.017488\n",
       "26           concavity_lg    0.033313\n",
       "27      concave points_lg    0.102010\n",
       "28            symmetry_lg    0.009165\n",
       "29   fractal dimension_lg    0.004870"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'column_name': X.columns, 'importance': grid_svc.best_estimator_.feature_importances_})\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search met een soft-voting SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_clf accuracy_score = 0.9647887323943662  TN = 85   FP = 2   FN = 3   TP = 52\n",
      "rnd_clf accuracy_score = 0.9647887323943662  TN = 85   FP = 2   FN = 3   TP = 52\n",
      "svm_clf accuracy_score = 0.9788732394366197  TN = 87   FP = 0   FN = 3   TP = 52\n",
      "vot_clf accuracy_score = 0.971830985915493  TN = 86   FP = 1   FN = 3   TP = 52\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(C=1, coef0=1, degree=2, kernel='poly', random_state=42, probability = True)\n",
    "vot_clf = VotingClassifier(estimators=[\n",
    "  ('log_clf', log_clf),\n",
    "  ('rnd_clf', rnd_clf),\n",
    "  ('svm_clf', svm_clf)], voting='soft')\n",
    "\n",
    "all_clf = [('log_clf', log_clf), ('rnd_clf', rnd_clf), ('svm_clf', svm_clf), ('vot_clf', vot_clf)]\n",
    "\n",
    "for clf_tuple in all_clf:\n",
    "  pipeline = Pipeline([\n",
    "    ('prep',col_transform),\n",
    "    (clf_tuple[0], clf_tuple[1])\n",
    "])\n",
    "\n",
    "  pipeline.fit(X_train, y_train)\n",
    "  y_pred = pipeline.predict(X_test)\n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "  print(f\"{clf_tuple[0]} accuracy_score = {accuracy_score(y_test, y_pred)}  TN = {tn}   FP = {fp}   FN = {fn}   TP = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Bag Classifier\n",
    "\n",
    "We gaan een BaggingClassifier opzetten om zo een logistisch model te verbeteren. De oob-score gaat berekend worden op data die niet perse gebruikt werd in de analyse van het model. Dit is verschillend met de validatiescore waarbij ieder element sowieso wordt gebruikt voor het trainen en/of testen, afhankelijk van moment. De kans is reÃ«el dat een instantie niet wordt gebruikt voor het trainen, testen of zelfs beide.\n",
    "\n",
    "1. We gaan een Pipeline maken met daarin eerst de voorbereiding (ColumnTransformer) en daarna de BaggingClassifier. Bij de BaggingClass. geven we het logistische regressiemodel mee. \n",
    "\n",
    "2. We trainen de pipeline en o.b.v. dit resultaat kunnen wij de nauwkeurigheid opvragen van het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De OoB-score is 0.9859154929577465\n",
      "De accuracy van het model is = 97.18%  TN = 86   FP = 1   FN = 3   TP = 52\n",
      "index = 72\tcorrect = M   predicted = 0   scores = [0.88061361 0.11938639]\n",
      "index = 412\tcorrect = B   predicted = 1   scores = [0.46889804 0.53110196]\n",
      "index = 296\tcorrect = M   predicted = 0   scores = [0.99459606 0.00540394]\n",
      "index = 39\tcorrect = M   predicted = 0   scores = [0.87744274 0.12255726]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "bag_clf = BaggingClassifier(log_reg, n_estimators=200, max_samples=150, bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('prep',col_transform),\n",
    "    ('bag_clf', bag_clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(f\"De OoB-score is {pipeline[1].oob_score_}\")\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_scores = pipeline.predict_proba(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(f\"De accuracy van het model is = {accuracy_score(y_test, y_pred):.2%}  TN = {tn}   FP = {fp}   FN = {fn}   TP = {tp}\")\n",
    "\n",
    "conf_mx = confusion_matrix(y_test, y_pred)\n",
    "labels = ['0','1']\n",
    "cf = sns.heatmap(conf_mx,square=True, annot=True, fmt='d', cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "cf.set_xlabel('Predicted class')\n",
    "cf.set_ylabel('Actual class')\n",
    "\n",
    "for ((index, correct), scores) in zip(y_test.items(), y_scores):\n",
    "  predicted = np.argmax(scores)\n",
    "  correct_0_1 = 0 if correct == 'B' else 1\n",
    "  if correct_0_1 != predicted:\n",
    "    print(f\"index = {index}\\tcorrect = {correct}   predicted = {predicted}   scores = {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen een overzicht krijgen van de fouten die iedere classifier kan maken.\n",
    "\n",
    "1. We hebben dezelfde classifiers van daarnet nodig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(C=1, coef0=1, degree=2, kernel='poly', random_state=42, probability = True)\n",
    "vot_clf = VotingClassifier(estimators=[\n",
    "  ('log_clf', log_clf),\n",
    "  ('rnd_clf', rnd_clf),\n",
    "  ('svm_clf', svm_clf)], voting='soft')\n",
    "\n",
    "all_clf = [('log_clf', log_clf), ('rnd_clf', rnd_clf), ('svm_clf', svm_clf), ('vot_clf', vot_clf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Met een for-lus gaan we iedere classifier gaan doorlopen. We gaan een Pipeline opbouwen met daarin de columntransformer, gevolgd door de classifier waarvan we de scores willen analyseren.\n",
    "\n",
    "3. Per classifier gaan we alle scores overlopen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_clf\n",
      "index = 72\tcorrect = M   predicted = 0   scores = [0.94310467 0.05689533]\n",
      "index = 412\tcorrect = B   predicted = 1   scores = [0.46301094 0.53698906]\n",
      "index = 296\tcorrect = M   predicted = 0   scores = [0.99852898 0.00147102]\n",
      "index = 39\tcorrect = M   predicted = 0   scores = [0.90895473 0.09104527]\n",
      "index = 362\tcorrect = B   predicted = 1   scores = [0.49671608 0.50328392]\n",
      "rnd_clf\n",
      "index = 72\tcorrect = M   predicted = 0   scores = [0.74 0.26]\n",
      "index = 296\tcorrect = M   predicted = 0   scores = [0.96 0.04]\n",
      "index = 39\tcorrect = M   predicted = 0   scores = [0.92 0.08]\n",
      "index = 132\tcorrect = B   predicted = 1   scores = [0.44 0.56]\n",
      "index = 362\tcorrect = B   predicted = 1   scores = [0.24 0.76]\n",
      "svm_clf\n",
      "index = 72\tcorrect = M   predicted = 0   scores = [0.93126412 0.06873588]\n",
      "index = 412\tcorrect = B   predicted = 1   scores = [0.49268302 0.50731698]\n",
      "index = 296\tcorrect = M   predicted = 0   scores = [0.99626815 0.00373185]\n",
      "index = 39\tcorrect = M   predicted = 0   scores = [0.84483184 0.15516816]\n",
      "vot_clf\n",
      "index = 72\tcorrect = M   predicted = 0   scores = [0.87145626 0.12854374]\n",
      "index = 296\tcorrect = M   predicted = 0   scores = [0.98493238 0.01506762]\n",
      "index = 39\tcorrect = M   predicted = 0   scores = [0.89126219 0.10873781]\n",
      "index = 362\tcorrect = B   predicted = 1   scores = [0.44374993 0.55625007]\n"
     ]
    }
   ],
   "source": [
    "for clf_tuple in all_clf:\n",
    "  pipeline = Pipeline([\n",
    "    ('prep',col_transform),\n",
    "    (clf_tuple[0], clf_tuple[1])\n",
    "])\n",
    "\n",
    "  pipeline.fit(X_train, y_train)\n",
    "  y_scores = pipeline.predict_proba(X_test)\n",
    "  print(f\"{clf_tuple[0]}\")\n",
    "\n",
    "  for ((index, correct), scores) in zip(y_test.items(), y_scores):\n",
    "    predicted = np.argmax(scores)\n",
    "    correct_0_1 = 0 if correct == 'B' else 1\n",
    "    if correct_0_1 != predicted:\n",
    "      print(f\"index = {index}\\tcorrect = {correct}   predicted = {predicted}   scores = {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: ExtraTreesClass, AdaBoostClass en GradientBoostingClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ext_clf accuracy_score = 0.9647887323943662  TN = 86   FP = 1   FN = 4   TP = 51\n",
      "ada_clf accuracy_score = 0.9647887323943662  TN = 87   FP = 0   FN = 5   TP = 50\n",
      "gbc_clf accuracy_score = 0.9507042253521126  TN = 85   FP = 2   FN = 5   TP = 50\n"
     ]
    }
   ],
   "source": [
    "ext_clf = ExtraTreesClassifier(n_estimators=150, random_state=42)\n",
    "ada_clf = AdaBoostClassifier(n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state = 42)\n",
    "gbc_clf = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "\n",
    "all_clf = [\n",
    "    ('ext_clf', ext_clf),\n",
    "    ('ada_clf', ada_clf),\n",
    "    ('gbc_clf', gbc_clf)\n",
    "]\n",
    "\n",
    "for clf_tuple in all_clf:\n",
    "  \n",
    "  pipeline = Pipeline([\n",
    "    ('prep',col_transform),\n",
    "    (clf_tuple[0], clf_tuple[1])\n",
    "])\n",
    "  \n",
    "  pipeline.fit(X_train, y_train)\n",
    "  y_pred = pipeline.predict(X_test)\n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "  print(f\"{clf_tuple[0]} accuracy_score = {accuracy_score(y_test, y_pred)}  TN = {tn}   FP = {fp}   FN = {fn}   TP = {tp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "461b8cd1ed42f26c365b05a87642eedf7a94d4e578d07d12c4b9e9e926e3307d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
